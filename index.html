
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>aDiner</title>
    <meta name="author" content="Yufu Zhou">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Bungee+Shade&family=Titillium+Web&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
</head>


<body>
<div class="main" style="max-width: 1080px;">
    
<div class="content">
<table>
<tbody>
<tr style="text-align:center">
    <td style="font-size: 250%; font-weight: bold; width:1080px">
        <span>aDiner</span>
        <br>
    <span style="line-height:100%; font-size: 80%; font-weight: bold">Adaptive Dynamic Implicit Neural Representation for Dynamic CBCT Imaging
    </td>
</tr>
<tr style="text-align:center">
    <td>
        <p style="font-size: 120%; line-height:100%;">
        <a href="https://github.com/Henryzyf">Yufu Zhou</a><sup style="color: #cb4b16; margin-right:0.4cm;">1</sup>
        Hua Chen<sup style="color: #859900;">2</sup><sup style="color: #d422a1; margin-right:0.4cm;">3</sup>
        <a href="https://github.com/ivy9092111111">Ziheng Deng</a><sup style="color: #cb4b16; margin-right:0.4cm;">1</sup>
        <a href="https://bme.sjtu.edu.cn/Web/FacultyDetail/76">Jun Zhao</a><sup style="color: #cb4b16; margin-right:0.4cm;">1</sup>
        </p>
        <p style="font-size: 90%;">
            <sup style="margin-left:0cm; color: #cb4b16;">1</sup> School of Biomedical Engineering, Shanghai Jiao Tong University
            <sup style="margin-left:0.5cm; color: #859900;">2</sup> School of Medicine, Shanghai Jiao Tong University
            <sup style="margin-left:0.5cm; color: #d422a1;">3</sup> Department of Radiation Oncology, Shanghai Chest Hospital
        </p>
    </td>
</tr>
</tbody>
</table>
</div>

<div class="content">
<h2 style="text-align:center">Video</h2>
<table>
<tbody>

<div class="video-container">
Reconstruction results in the simulated regular respiration
<video width="768" height="460" controls>
     <source src="https://github.com/Henryzyf/aDiner/raw/refs/heads/main/simulated_regular.mp4" type="video/mp4">
    Your browser does not support the video tag.
</video>
</div>
    
<div class="video-container">
Reconstruction results in the simulated irregular respiration
<video width="768" height="460" controls>
     <source src="https://github.com/Henryzyf/aDiner/raw/refs/heads/main/simulated_irregular.mp4" type="video/mp4">
    Your browser does not support the video tag.
</video>
</div>

<div class="video-container">
Reconstruction results in one clinical scan of Varian Truebeam system from Shanghai Chest Hospital
<video width="768" height="252" controls>
     <source src="https://github.com/Henryzyf/aDiner/raw/refs/heads/main/xkyy_221556_3views.mp4" type="video/mp4">
    Your browser does not support the video tag.
</video>
</div>
    
</tbody>   
</table>
</div>

<div class="content">
<h2 style="text-align:center">Abstract</h2>
<table>
<tbody>
<tr>
    <td>Cone-beam Computed Tomography (CBCT) is essential for target localization and treatment planning in image-guided radiotherapy for lung cancer. Dynamic reconstruction is an ill-posed inverse problem, as each motion state is captured by only one single projection. Although several deep learning methods have been proposed, most algorithms rely on training by large datasets with high-quality ground-truth labels and reconstruct images at discrete respiratory phases. Therefore, we propose a self-supervised learning method, adaptive Dynamic implicit neural representation (aDiner), to reconstruct dynamic CBCT images for each timepoint. Specifically, an adaptive composite representation (ACR) is introduced for dynamic CBCT. In ACR, the inter- and intra-cycle encoding (iICE) captures the inter- and intra-cycle similarities of lung motion and ensures temporal coherence. Moreover, a probability-based feature fusion (PFF) is proposed to fuse decoupled static and dynamic features, composing the spatiotemporal representation. To improve the motion estimation, we further design a motion-guided coarse-to-fine sampling (MCS) strategy to focus on dynamic regions with adaptive projection-ray sampling (APS) and adaptive deformed-point sampling (ADS). Compared with the previous methods, aDiner takes advantage of the inter- and intra-cycle similarities and separately estimates static and dynamic regions to achieve better reconstruction quality. aDiner was evaluated on simulated and clinical datasets. The results showed that aDiner could accurately and robustly reconstruct dynamic CBCTs for each timepoint and capture the lung motion in both regular and irregular respirations.</td>
</tr>
<!--
<tr style="text-align:center">
    <td><img src='aDiner-framework.png' width="100%"></td>
</tr>
-->
</tbody>
</table>
</div>

</div>
</body>

<script src="copy.js"></script>
<script src="script.js"></script>
